{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune Mistral 7B Instruct Model\n",
        "\n",
        "The model we train will learn how to retrieve documents from our context documents and generate responses in a unified system.\n",
        "\n",
        "We will:\n",
        "\n",
        "* Install dependencies\n",
        "* [Prepare a dataset](https://github.com/Uliana-Liakh/Fine-tune_LLM_QA/blob/main/Prepare_dataset.ipynb)\n",
        "* Test Prompts\n",
        "* Fine-tune the Mistral 7B Instruct Model\n",
        "* Evaluate fine-tuning model\n"
      ],
      "metadata": {
        "id": "xKt-KmBLD1qE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install"
      ],
      "metadata": {
        "id": "OmcPFFX3Zzr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDE2rdBYHrGd",
        "outputId": "954bb717-a687-4761-9288-594a15f0a792"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers trl accelerate torch bitsandbytes peft datasets evaluate rouge-score vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWzuy1QjZfHY",
        "outputId": "eed19a42-4955-440e-bc35-0931d0de8851"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-re2rt7ba\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-re2rt7ba\n",
            "  Resolved https://github.com/huggingface/transformers to commit f213d5dd8cea1eb31d9b44dbdf268e4265a6d338\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.41.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.2.1.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: tyro>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from trl) (0.5.12)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from vllm) (1.11.1.1)\n",
            "Requirement already satisfied: ray>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.99)\n",
            "Requirement already satisfied: xformers==0.0.22 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.22)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from vllm) (0.104.1)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.24.0.post1)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.10.13)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm) (3.20.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl) (0.15)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl) (13.6.0)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl) (1.6.4)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->vllm) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->vllm) (0.27.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm) (1.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl) (2.16.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm) (0.11.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9ryBTdkZE38p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from trl import SFTTrainer\n",
        "from random import randrange\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
        "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import accelerate\n",
        "from google.colab import drive\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "from huggingface_hub import notebook_login\n",
        "import evaluate\n",
        "import re\n",
        "\n",
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKbgcHO4GrQa"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_full_clean = pd.read_csv('/content/drive/MyDrive/culture_train_982_clean.csv')\n",
        "df_full_clean = df_full_clean.drop(['Unnamed: 0', 'Abstract'], axis=1)\n",
        "df_full_clean.columns = df_full_clean.columns.str.lower()\n",
        "df_full_clean.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "ss1vjASQ_JJe",
        "outputId": "ce9ad26d-2fa4-450b-bd82-d420787021e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  Why do some cultures, such as Latin American a...   \n",
              "1  What is the concept of \"constructive criticism...   \n",
              "2  How can exploring and discussing the differenc...   \n",
              "3  How does making an investment up front benefit...   \n",
              "4  Explain the principles-first and applications-...   \n",
              "\n",
              "                                              answer  \n",
              "0  Some cultures, such as Latin American and Midd...  \n",
              "1  The concept of \"constructive criticism\" refers...  \n",
              "2  Exploring and discussing the differences in va...  \n",
              "3  Making an investment up front benefits individ...  \n",
              "4  The principles-first cultural tendency refers ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-534d826c-e689-4e58-9edc-dbe6abd4ef90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why do some cultures, such as Latin American a...</td>\n",
              "      <td>Some cultures, such as Latin American and Midd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the concept of \"constructive criticism...</td>\n",
              "      <td>The concept of \"constructive criticism\" refers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can exploring and discussing the differenc...</td>\n",
              "      <td>Exploring and discussing the differences in va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does making an investment up front benefit...</td>\n",
              "      <td>Making an investment up front benefits individ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Explain the principles-first and applications-...</td>\n",
              "      <td>The principles-first cultural tendency refers ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-534d826c-e689-4e58-9edc-dbe6abd4ef90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-534d826c-e689-4e58-9edc-dbe6abd4ef90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-534d826c-e689-4e58-9edc-dbe6abd4ef90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb5ae86d-0e9a-467b-bce2-f0524da93810\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb5ae86d-0e9a-467b-bce2-f0524da93810')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb5ae86d-0e9a-467b-bce2-f0524da93810 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ACOa0U5eF21J"
      },
      "outputs": [],
      "source": [
        "datasets=df_full_clean[:400]\n",
        "train_dataset = datasets\n",
        "test_dataset = df_full_clean[400:410]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G91J6bn6ZTXG"
      },
      "outputs": [],
      "source": [
        "datasets=Dataset.from_pandas(datasets)\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BJw31B80QtdX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmZk9LAIIjxB"
      },
      "source": [
        "### Mistral 7B Instruct Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "058e2bba4b804b6fb2fd5440e01bee6b",
            "5fae617f731846b59b6299942f03fd4e",
            "5516e987f93145ebbff6aaca5afe3366",
            "d8a05dc91b0c4244ac327970f61da1f1",
            "aeea6b8c6e194c4f84052131874a2505",
            "d56517e834d046d9b80ebb9d914576c0",
            "3cf6893fd461489d8a01c26e784ec37b",
            "591c9157b9fd495ea27817aa15e164a7",
            "f683378b26f948ceb3102d7d1c2de49d",
            "5732cb40fb0f4d49848c924783ff7c97",
            "e5ebc489ac11450997fada0b438af201"
          ]
        },
        "id": "OMtJSjflZTXH",
        "outputId": "29a715da-2718-4c2a-b9d2-c7087158e0ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "058e2bba4b804b6fb2fd5440e01bee6b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import model and tokenizer\n",
        "# loading only 4-bit version\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "                                             device_map='auto',\n",
        "                                             load_in_4bit=True, use_cache=False)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A prompting formatting function\n",
        "def create_prompt_instruction(sample):\n",
        "   return f\"\"\"### Instruction:\n",
        "   Use the input below to create an instruction, which could have been used to generate the input using an LLM.\n",
        "\n",
        "   ### Input\n",
        "   {sample['answer']}\n",
        "\n",
        "   ### Response:\n",
        "   {sample['question']}\n",
        "   \"\"\"\n"
      ],
      "metadata": {
        "id": "gSb8km-tIFbq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_prompt_instruction(datasets[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spCDHYSfINkw",
        "outputId": "5678ff58-60de-4a27-c000-c4c96ba49cfc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "   Use the input below to create an instruction, which could have been used to generate the input using an LLM.\n",
            "\n",
            "   ### Input\n",
            "   Some cultures, such as Latin American and Middle Eastern cultures, may find it difficult to separate personal emotions from disagreements due to several factors. One possible reason is the emphasis on collectivism in these cultures, where the needs and interests of the group are prioritized over individual desires. This collective mindset can lead to a stronger emotional investment in disagreements, as individuals may feel personally attacked or threatened when their opinions or beliefs are challenged.\n",
            "\n",
            "   ### Response:\n",
            "   Why do some cultures, such as Latin American and Middle Eastern cultures, find it difficult to separate personal emotions from disagreements?\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3GkgXI-hZTXH"
      },
      "outputs": [],
      "source": [
        "def get_prompt():\n",
        "\n",
        "    \"\"\"\n",
        "    Select a random sample from a dataset and format it into a prompt for language model (LLM) instruction generation.\n",
        "\n",
        "    This function randomly selects an index, retrieves a sample from a dataset, and formats a prompt string that instructs to create an LLM instruction based on the sample's response. The formatted prompt and the selected sample are returned.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - str: A formatted string that includes an instruction and the response from the randomly selected sample, intended to be used as a prompt for LLM instruction generation.\n",
        "        - dict: The randomly selected sample from the dataset.\n",
        "\n",
        "    Note:\n",
        "    Ensure that 'dataset' is a pre-defined list of dictionaries, where each dictionary contains at least a key 'response' holding a text string. The function does not handle empty datasets or missing keys and may raise an exception in such cases.\n",
        "    \"\"\"\n",
        "\n",
        "    idx = randrange(len(datasets))\n",
        "\n",
        "    sample = datasets[idx]\n",
        "\n",
        "    return f\"\"\"### Instruction:\n",
        "    Use the input below to create an instruction, which could have been used to generate the input using an LLM.\n",
        "\n",
        "    ### Input\n",
        "    {sample['answer']}\n",
        "\n",
        "    ### Response:\n",
        "    \"\"\", sample\n",
        "\n",
        "\n",
        "\n",
        "def get_response(prompt, sample):\n",
        "\n",
        "    \"\"\"\n",
        "    Generate a response based on a given prompt using an LLM.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): A text string to prompt LLM.\n",
        "    - sample (dict): A dictionary containing a ground truth.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing:\n",
        "        - 'LLM result': The generated response from the language model, decoded from token IDs to a string.\n",
        "        - 'ground truth': The ground truth instruction text extracted from the input sample.\n",
        "\n",
        "    Note:\n",
        "    Ensure that the 'tokenizer' and 'model' are loaded.\n",
        "    \"\"\"\n",
        "\n",
        "    encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "    model_inputs = encoded_input.to(\"cuda:0\")\n",
        "\n",
        "    generated_ids = model.generate(**model_inputs, max_new_tokens=1000,\n",
        "                                   do_sample=True,\n",
        "                                   pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "    return {\n",
        "      'llm_response': decoded_output[0], # LLM-generated response\n",
        "      'reference': sample['question'] # Ground Truth\n",
        "       }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUcH6u4GZTXH"
      },
      "source": [
        "#### Test Prompt 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9yLFv4OZTXH",
        "outputId": "f6cb19a4-c008-4684-ce70-7dd16622954e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# TEST PROMPT \n",
            "### Instruction: \n",
            "    Use the input below to create an instruction, which could have been used to generate the input using an LLM. \n",
            "\n",
            "    ### Input \n",
            "    The differing decision-making styles of Americans and Germans can impact the timeline of a typical project in several ways. Americans tend to have a more fast-paced and action-oriented decision-making style, often prioritizing efficiency and quick results. On the other hand, Germans tend to have a more thorough and cautious decision-making style, emphasizing careful analysis and consensus-building.\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "LLM result:\n",
            "<s> ### Instruction: \n",
            "    Use the input below to create an instruction, which could have been used to generate the input using an LLM. \n",
            "\n",
            "    ### Input \n",
            "    The differing decision-making styles of Americans and Germans can impact the timeline of a typical project in several ways. Americans tend to have a more fast-paced and action-oriented decision-making style, often prioritizing efficiency and quick results. On the other hand, Germans tend to have a more thorough and cautious decision-making style, emphasizing careful analysis and consensus-building.\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "    Write an instruction that highlights the differences in decision-making styles between Americans and Germans and describes how these differences can impact a project's timeline. In your response, include examples of fast-paced vs. thorough decision-making styles and discuss the importance of each in the context of a project. Additionally, explain how a project's timeline may be affected by these differences, and provide examples of possible outcomes.</s>\n",
            "--------------------------------------------------------------------------------\n",
            "Ground truth:\n",
            "How do the differing decision-making styles of Americans and Germans impact the timeline of a typical project?\n"
          ]
        }
      ],
      "source": [
        "# Get the prompt first\n",
        "print('# TEST PROMPT')\n",
        "test_prompt, sample = get_prompt()\n",
        "print(test_prompt)\n",
        "\n",
        "# Get the response\n",
        "response = get_response(test_prompt, sample)\n",
        "\n",
        "# print the llm response and ground truth\n",
        "print(\"LLM result:\")\n",
        "print(response['llm_response'])\n",
        "print('--'*40)\n",
        "print(\"Ground truth:\")\n",
        "print(response['reference'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXw5DochZTXH"
      },
      "source": [
        "#### Test Prompt 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkKyJ5udZTXH",
        "outputId": "3787b2e1-10cf-47a4-80a9-f3ce5b5dcb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# TEST PROMPT\n",
            "### Instruction: \n",
            "    Use the input below to create an instruction, which could have been used to generate the input using an LLM. \n",
            "\n",
            "    ### Input \n",
            "    The Chinese and Japanese cultures value harmony and maintaining positive relationships. Direct negative feedback and open disagreement can be seen as confrontational and may damage these relationships. Therefore, they tend to avoid such situations to preserve harmony and maintain a respectful atmosphere.\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "LLM result:\n",
            "<s> ### Instruction: \n",
            "    Use the input below to create an instruction, which could have been used to generate the input using an LLM. \n",
            "\n",
            "    ### Input \n",
            "    The Chinese and Japanese cultures value harmony and maintaining positive relationships. Direct negative feedback and open disagreement can be seen as confrontational and may damage these relationships. Therefore, they tend to avoid such situations to preserve harmony and maintain a respectful atmosphere.\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "    In order to avoid negative feedback and maintain positive relationships in Chinese and Japanese cultures, it is best to approach disagreement and feedback in a respectful manner. Being direct and critical can be perceived as confrontational and harmful, so it is recommended to find a tactful way to express your thoughts and concerns. This can help preserve harmony and maintain a respectful atmosphere.</s>\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Ground truth:\n",
            "Why are the Chinese and Japanese uncomfortable with direct negative feedback and open disagreement?\n"
          ]
        }
      ],
      "source": [
        "# Get the prompt first\n",
        "print('# TEST PROMPT')\n",
        "test_prompt, sample = get_prompt()\n",
        "print(test_prompt)\n",
        "\n",
        "# Get the response\n",
        "response = get_response(test_prompt, sample)\n",
        "\n",
        "# print the llm response and ground truth\n",
        "print(\"LLM result:\")\n",
        "print(response['llm_response'])\n",
        "print('--'*60)\n",
        "print(\"Ground truth:\")\n",
        "print(response['reference'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CtSXI_KdIB0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi1ayN1-ZTXI"
      },
      "source": [
        "### Fine-tuning the Mistral 7B Instruct Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7otBVj7ZTXI"
      },
      "source": [
        "Finetuning the entire model demands a massive GPU, so I will use the PEFT (Parameter Efficient FineTuning) technique — LoRA (Low-Rank Adaptation), which freezes the pre-trained model and adds smaller trainable matrices to each layer.\n",
        "\n",
        "Финишная настройка всей модели требует большого GPU, поэтому я использую технику PEFT (Parameter Efficient FineTuning) - LoRA (Low-Rank Adaptation), которая замораживает предварительно обученную модель и добавляет в каждый слой более мелкие обучаемые матрицы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DQfCrb8iZTXI"
      },
      "outputs": [],
      "source": [
        "# PEFT Config\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Prepare the model for finetuning\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "39MwOm6EZTXI"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir = \"mistral_instruct_qa\",\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size = 1,\n",
        "    warmup_steps = 0.03,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type='constant',\n",
        "    disable_tqdm=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zUi4pzbKZTXI"
      },
      "outputs": [],
      "source": [
        "# Define SFTTrainer arguments\n",
        "max_seq_length = 2048\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    formatting_func= create_prompt_instruction,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finetune 1\n",
        "trainer.train()\n",
        "\n",
        "# Save finetuned model\n",
        "trainer.save_model(\"mistral_instruct_qa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWnSGUPDBtWN",
        "outputId": "65ca19ab-c734-4269-c848-d0c4b0773ea5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.003, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.8241, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7273, 'learning_rate': 0.0002, 'epoch': 1.01}\n",
            "{'loss': 0.6596, 'learning_rate': 0.0002, 'epoch': 1.03}\n",
            "{'loss': 0.6487, 'learning_rate': 0.0002, 'epoch': 1.06}\n",
            "{'loss': 0.5388, 'learning_rate': 0.0002, 'epoch': 2.02}\n",
            "{'loss': 0.5188, 'learning_rate': 0.0002, 'epoch': 2.04}\n",
            "{'loss': 0.4811, 'learning_rate': 0.0002, 'epoch': 3.0}\n",
            "{'loss': 0.3675, 'learning_rate': 0.0002, 'epoch': 3.03}\n",
            "{'loss': 0.3534, 'learning_rate': 0.0002, 'epoch': 3.06}\n",
            "{'loss': 0.2984, 'learning_rate': 0.0002, 'epoch': 4.01}\n",
            "{'loss': 0.2356, 'learning_rate': 0.0002, 'epoch': 4.04}\n",
            "{'loss': 0.2875, 'learning_rate': 0.0002, 'epoch': 4.07}\n",
            "{'train_runtime': 344.0005, 'train_samples_per_second': 5.814, 'train_steps_per_second': 5.814, 'train_loss': 0.5341251978507409, 'epoch': 4.07}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finetune 2\n",
        "trainer.train()\n",
        "\n",
        "# Save finetuned model\n",
        "trainer.save_model(\"mistral_instruct_qa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKZv17GsIwnG",
        "outputId": "c6d210ba-8191-4468-fc21-eb9f9ba9f369"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.0035, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
            "{'loss': 0.8241, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
            "{'loss': 0.7267, 'learning_rate': 0.0002, 'epoch': 1.01}\n",
            "{'loss': 0.6615, 'learning_rate': 0.0002, 'epoch': 1.03}\n",
            "{'loss': 0.6511, 'learning_rate': 0.0002, 'epoch': 1.06}\n",
            "{'loss': 0.5478, 'learning_rate': 0.0002, 'epoch': 2.02}\n",
            "{'loss': 0.5215, 'learning_rate': 0.0002, 'epoch': 2.04}\n",
            "{'loss': 0.4832, 'learning_rate': 0.0002, 'epoch': 3.0}\n",
            "{'loss': 0.3805, 'learning_rate': 0.0002, 'epoch': 3.03}\n",
            "{'loss': 0.3567, 'learning_rate': 0.0002, 'epoch': 3.06}\n",
            "{'loss': 0.3085, 'learning_rate': 0.0002, 'epoch': 4.01}\n",
            "{'loss': 0.2539, 'learning_rate': 0.0002, 'epoch': 4.04}\n",
            "{'loss': 0.2911, 'learning_rate': 0.0002, 'epoch': 4.07}\n",
            "{'train_runtime': 344.0069, 'train_samples_per_second': 5.814, 'train_steps_per_second': 5.814, 'train_loss': 0.5392427811255822, 'epoch': 4.07}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxqehLWIZTXI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate and compare the base model responses & finetuned model responses"
      ],
      "metadata": {
        "id": "GqL2XoHPwF-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(sample):\n",
        "\n",
        "    return f\"\"\"### Instruction:\n",
        "    Use the input below to create an instruction, which could have been used to generate the input using an LLM.\n",
        "\n",
        "    ### Input\n",
        "    {sample['answer']}\n",
        "\n",
        "    ### Response:\n",
        "    \"\"\", sample"
      ],
      "metadata": {
        "id": "FBCBn1PPHwtL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get references / Ground Truth the model will be evaluated against\n",
        "references = [sample['question'] for sample in test_dataset]"
      ],
      "metadata": {
        "id": "Rn8EHL8sDolj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate origin model responses"
      ],
      "metadata": {
        "id": "W1Dvfdqktvqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading origin model\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "                                             device_map=\"auto\",load_in_4bit=True,\n",
        "                                             use_cache=False)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f3ceca5d740645ed8bfcc55549bd4b0c",
            "023465862f1b410a95d113ede0b5bef7",
            "b1ad27c500b24f5fa3aafec3c54892eb",
            "ba37d0dd219345a18c5c9b292ff1e404",
            "4bfd2bd558914ec8bf7d9c570fe3a60c",
            "1098dec122a4490bbdfcada0ddf46ef7",
            "07cf02c3b4a24f4dabaa164c4a45fabe",
            "e601953044804650a661afc2f7d3a917",
            "dd92b5bfe4044fefa6fee8f17e2a2534",
            "f2e8525d4c0243b09b01a483aef3347b",
            "68ccc5c214f54fdcbb359da78d887854"
          ]
        },
        "id": "IKAOc6ygt4sQ",
        "outputId": "3b7cd5da-dee5-4747-c2c4-d3629c33093f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3ceca5d740645ed8bfcc55549bd4b0c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt, sample):\n",
        "\n",
        "    \"\"\"\n",
        "    Generate a response based on a given prompt using an LLM.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): A text string to prompt LLM.\n",
        "    - sample (dict): A dictionary containing a ground truth.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing:\n",
        "        - 'LLM result': The generated response from the language model, decoded from token IDs to a string.\n",
        "        - 'ground truth': The ground truth instruction text extracted from the input sample.\n",
        "\n",
        "    Note:\n",
        "    Ensure that the 'tokenizer' and 'model' are loaded.\n",
        "    \"\"\"\n",
        "\n",
        "    encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_inputs = encoded_input.to(device)\n",
        "\n",
        "    generated_ids = model.generate(**model_inputs, max_new_tokens=1000,\n",
        "                                   do_sample=True,\n",
        "                                   pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "    return {\n",
        "      'llm_response': decoded_output[0], # LLM-generated response\n",
        "      'reference': sample['question'] # Ground Truth\n",
        "       }"
      ],
      "metadata": {
        "id": "hqeR5lNzrZDv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses_base_model = []\n",
        "\n",
        "for sample in test_dataset:\n",
        "    prompt, _ = get_prompt(sample)\n",
        "    response = get_response(prompt, sample)\n",
        "    txt = re.sub(r\"\\n\", \"\", response['llm_response'])\n",
        "    txt1 = txt.split(\"Response:\")[1]\n",
        "    result = txt1.split(\"</s>\")[0]\n",
        "    print(result)\n",
        "    responses_base_model.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZZLyc3u-p25",
        "outputId": "bfb2a9b3-48a2-461f-e3b0-a82df0897a1b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1553: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        To learn a language using the applications-first approach, focus on using the language in practical situations from the start. Emphasize developing practical language proficiency and communication skills through activities such as conversations, role-plays, and real-world scenarios. This method will help you become fluent in the language quickly.\n",
            "        To generate text based on the given instruction, please create a response that explains how common human emotions can bring people from diverse backgrounds together. Provide examples of such emotions and how they can connect individuals from different cultures.\n",
            "        Use the input below to explain how language and history impact communication styles in different cultures:    In many cultures, language and history are closely intertwined, influencing the vocabulary, grammar, and expressions used in a particular language. Historical events, cultural traditions, and societal norms are reflected in the language, shaping communication styles and influencing how people understand each other within a specific culture. For example, in cultures with a long history of hierarchical social structures, language may include specific honorifics or formal speech patterns to show respect and maintain social order. Similarly, historical conflicts or colonial influences can lead to the adoption of foreign words or expressions, creating a unique linguistic blend. Overall, the interplay of language and history significantly impacts communication styles in different cultures.\n",
            "    1. Observe and listen carefully to understand the local language, culture, business practices, and regulations.    2. Learn and adapt to the local market dynamics.    3. Build relationships with local stakeholders including business partners, suppliers, and customers.    4. Foster a diverse workforce and manage their different backgrounds and experiences.    5. Use technology and resources, such as translation software, to overcome language barriers.    6. Network and seek mentorship from professionals who are familiar with the local region and industry.    7. Stay updated on the latest trends and developments in the industry and region.     8. Develop cross-cultural communication and negotiation skills.    9. Be open-minded and open to new perspectives, values, and ways of doing things.    10. Build trust and credibility through actions and behaviors, not just words.\n",
            "        1. Begin by outlining a hypothetical scenario in which you are working with a group of individuals who are attempting to reach a consensus.     2. Use the word \"challenged\" to describe your initial perception of the process, highlighting that it was not what you expected it to be like.     3. Provide a brief description of what specifically challenged your initial perception, in order to give the reader a sense of what you were thinking.     4. Use the word \"showed\" to indicate that you received new information that caused your perspective to change.     5. Describe the new information that caused your perspective to shift, highlighting how it revealed that the consensus-building process was not as slow and time-consuming as you initially thought.     6. End your instruction by emphasizing the importance of this revelation and its impact on future interactions with others.\n",
            "        Write an instruction using the input above.\n",
            "        \"To create a relationship-building activity in an American-style training program or conference, consider using icebreaker activities, team-building exercises, networking events, group discussions, collaborative projects, mentorship programs, and social activities such as dinners or receptions as common examples.\"\n",
            "        Managers working in global businesses may be advised to adopt behaviors that align with their company’s culture and policies, rather than trying to fit in with typical American management styles. This will help to avoid misunderstandings and promote effective communication among team members. Additionally, it’s important for managers to be aware of potential cultural differences when leading teams in diverse locations, and to adapt their management practices accordingly.\n",
            "        How can I generate a paragraph about the significance of Confucius in shaping hierarchical cultures in Asian countries? What are some specific concepts and teachings that Confucius promoted that influenced the development of Confucianism?\n",
            "    1. Start by understanding the cultural differences and practices in the Netherlands.    2. Adopt a more collaborative and consultative approach to team leadership.    3. Encourage open communication and feedback.    4. Provide opportunities for team members to take ownership and initiative.    5. Foster a sense of responsibility and accountability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate finetuned model responses"
      ],
      "metadata": {
        "id": "4cSTOj-ouEWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the finetuned model\n",
        "finetuned_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    \"mistral_instruct_qa\",\n",
        "    low_cpu_mem_usage=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistral_instruct_qa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "69428ef7c4964be8be652cc172e88a34",
            "ed2a6f7861a545958985c4a3b4ea2215",
            "d65ee576ab804fb1a150b0f224148f26",
            "7f5f026876bc443aa6d31d65e8173ceb",
            "0c70df7c95f7493b892797d7324b6111",
            "3ce5259d7294430cb6edd545e7ff8d08",
            "541b2e7d18384849bb7138445a50765f",
            "7bc573d00e224fcda3448d956c13d3bf",
            "4ef551506bcb428493e9c24cc65fdc24",
            "8a6dc560545d47b4a66f8f15c013e498",
            "6e1fba05d5d9406c884358ee4406ed29"
          ]
        },
        "id": "nU5ZvXVr91Ja",
        "outputId": "d5562f6a-1430-49d5-8977-ac6c472b9a1c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69428ef7c4964be8be652cc172e88a34"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt, sample):\n",
        "\n",
        "    \"\"\"\n",
        "    Generate a response based on a given prompt using an LLM.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): A text string to prompt LLM.\n",
        "    - sample (dict): A dictionary containing a ground truth.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing:\n",
        "        - 'LLM result': The generated response from the language model, decoded from token IDs to a string.\n",
        "        - 'ground truth': The ground truth instruction text extracted from the input sample.\n",
        "\n",
        "    Note:\n",
        "    Ensure that the 'tokenizer' and 'model' are loaded.\n",
        "    \"\"\"\n",
        "\n",
        "    encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_inputs = encoded_input.to(device)\n",
        "\n",
        "    generated_ids = finetuned_model.generate(**model_inputs, max_new_tokens=1000,\n",
        "                                   do_sample=True,\n",
        "                                   pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "    return {\n",
        "      'llm_response': decoded_output[0], # LLM-generated response\n",
        "      'reference': sample['question'] # Ground Truth\n",
        "       }"
      ],
      "metadata": {
        "id": "bCVk7VuDuaUi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses_fn_model = []\n",
        "\n",
        "for sample in test_dataset:\n",
        "    prompt, _ = get_prompt(sample)\n",
        "    response = get_response(prompt, sample)\n",
        "    txt = re.sub(r\"\\n\", \"\", response['llm_response'])\n",
        "    txt1 = txt.split(\"Response:\")[1]\n",
        "    result = txt1.split(\"</s>\")[0]\n",
        "    print(result)\n",
        "    responses_fn_model.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb5Asba1ukRt",
        "outputId": "227fdb08-15d8-494b-d4eb-ff5b6caba59d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     What is the applications-first method of learning a language and how does it aim to develop practical language proficiency and communication skills?   \n",
            "     How can common human emotions such as jealousy, excitement, sorrow, and passion connect individuals from different cultures?   \n",
            "     How does the interplay of language and history influence communication styles in different cultures?     \n",
            "     What challenges might European managers face when working in different regions of China?   \n",
            "     How did the author's experience working with a group of Swedes challenge their initial perception of consensus-building?   \n",
            "     Why does the author focus only on the first two documents when giving feedback to their colleague?   \n",
            "     What are some examples of relationship-building activities commonly seen in American-style training programs or conferences?   \n",
            "     Why did managers working in global business feel the need to work in a more American manner?   \n",
            "     How did Confucius shape hierarchical cultures in Asian countries?    \n",
            "     What does Carlos Gomez believe is the wrong way to lead his Dutch team?   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We use the Rouge score to evaluate and compare the base model responses, finetuned model responses, and references (ground truth)."
      ],
      "metadata": {
        "id": "l9AJLYKTzVDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base model evaluation\n",
        "base_model_evaluation = rouge.compute(predictions=responses_base_model,\n",
        "                                      references=references)\n",
        "\n",
        "# Print 'rouge1', 'rouge2', and 'rougeL'\n",
        "print(\"Rouge-1 Evaluation:\")\n",
        "print(base_model_evaluation[\"rouge1\"])\n",
        "print(\"--\"*20)\n",
        "print(\"Rouge-2 Evaluatiom:\")\n",
        "print(base_model_evaluation[\"rouge2\"])\n",
        "print(\"--\"*20)\n",
        "print(\"Rouge-L Evaluation:\")\n",
        "print(base_model_evaluation[\"rougeL\"])"
      ],
      "metadata": {
        "id": "CKpGxgTjzYJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ba7b28-f5ec-47cb-8979-470c3e028473"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rouge-1 Evaluation:\n",
            "0.20895824664601048\n",
            "----------------------------------------\n",
            "Rouge-2 Evaluatiom:\n",
            "0.10110800390965681\n",
            "----------------------------------------\n",
            "Rouge-L Evaluation:\n",
            "0.187283652250661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetuned model evaluation\n",
        "finetuned_model_evaluation = rouge.compute(predictions=responses_fn_model,\n",
        "                                           references=references)\n",
        "\n",
        "# Print 'rouge1', 'rouge2', and 'rougeL'\n",
        "print(\"Rouge-1 Evaluation:\")\n",
        "print(finetuned_model_evaluation[\"rouge1\"])\n",
        "print(\"--\"*20)\n",
        "print(\"Rouge-2 Evaluation:\")\n",
        "print(finetuned_model_evaluation[\"rouge2\"])\n",
        "print(\"--\"*20)\n",
        "print(\"Rouge-L Evaluation:\")\n",
        "print(finetuned_model_evaluation[\"rougeL\"])"
      ],
      "metadata": {
        "id": "-HxLMa3OzdBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212786cd-a517-4031-b494-8525b3611991"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rouge-1 Evaluation:\n",
            "0.8803648515108963\n",
            "----------------------------------------\n",
            "Rouge-2 Evaluation:\n",
            "0.8205802745469929\n",
            "----------------------------------------\n",
            "Rouge-L Evaluation:\n",
            "0.8741808394445313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusions:\n",
        "In the evaluation phase, it is clear that the score of the Mistral 7B Instruct Model Rouge has improved significantly after fine-tuning. It is important to note that this comparison is between a 4-bit quantized fine-tuned model and a full Mistral 7B Instruct model."
      ],
      "metadata": {
        "id": "UKrb6GgARZzG"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "collapsed_sections": [
        "OmcPFFX3Zzr0",
        "PKbgcHO4GrQa",
        "hXw5DochZTXH",
        "W1Dvfdqktvqh"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "058e2bba4b804b6fb2fd5440e01bee6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fae617f731846b59b6299942f03fd4e",
              "IPY_MODEL_5516e987f93145ebbff6aaca5afe3366",
              "IPY_MODEL_d8a05dc91b0c4244ac327970f61da1f1"
            ],
            "layout": "IPY_MODEL_aeea6b8c6e194c4f84052131874a2505"
          }
        },
        "5fae617f731846b59b6299942f03fd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56517e834d046d9b80ebb9d914576c0",
            "placeholder": "​",
            "style": "IPY_MODEL_3cf6893fd461489d8a01c26e784ec37b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5516e987f93145ebbff6aaca5afe3366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591c9157b9fd495ea27817aa15e164a7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f683378b26f948ceb3102d7d1c2de49d",
            "value": 2
          }
        },
        "d8a05dc91b0c4244ac327970f61da1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5732cb40fb0f4d49848c924783ff7c97",
            "placeholder": "​",
            "style": "IPY_MODEL_e5ebc489ac11450997fada0b438af201",
            "value": " 2/2 [00:17&lt;00:00,  8.33s/it]"
          }
        },
        "aeea6b8c6e194c4f84052131874a2505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56517e834d046d9b80ebb9d914576c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf6893fd461489d8a01c26e784ec37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "591c9157b9fd495ea27817aa15e164a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f683378b26f948ceb3102d7d1c2de49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5732cb40fb0f4d49848c924783ff7c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ebc489ac11450997fada0b438af201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3ceca5d740645ed8bfcc55549bd4b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_023465862f1b410a95d113ede0b5bef7",
              "IPY_MODEL_b1ad27c500b24f5fa3aafec3c54892eb",
              "IPY_MODEL_ba37d0dd219345a18c5c9b292ff1e404"
            ],
            "layout": "IPY_MODEL_4bfd2bd558914ec8bf7d9c570fe3a60c"
          }
        },
        "023465862f1b410a95d113ede0b5bef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1098dec122a4490bbdfcada0ddf46ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_07cf02c3b4a24f4dabaa164c4a45fabe",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b1ad27c500b24f5fa3aafec3c54892eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e601953044804650a661afc2f7d3a917",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd92b5bfe4044fefa6fee8f17e2a2534",
            "value": 2
          }
        },
        "ba37d0dd219345a18c5c9b292ff1e404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e8525d4c0243b09b01a483aef3347b",
            "placeholder": "​",
            "style": "IPY_MODEL_68ccc5c214f54fdcbb359da78d887854",
            "value": " 2/2 [00:16&lt;00:00,  7.94s/it]"
          }
        },
        "4bfd2bd558914ec8bf7d9c570fe3a60c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1098dec122a4490bbdfcada0ddf46ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07cf02c3b4a24f4dabaa164c4a45fabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e601953044804650a661afc2f7d3a917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd92b5bfe4044fefa6fee8f17e2a2534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2e8525d4c0243b09b01a483aef3347b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ccc5c214f54fdcbb359da78d887854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69428ef7c4964be8be652cc172e88a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed2a6f7861a545958985c4a3b4ea2215",
              "IPY_MODEL_d65ee576ab804fb1a150b0f224148f26",
              "IPY_MODEL_7f5f026876bc443aa6d31d65e8173ceb"
            ],
            "layout": "IPY_MODEL_0c70df7c95f7493b892797d7324b6111"
          }
        },
        "ed2a6f7861a545958985c4a3b4ea2215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce5259d7294430cb6edd545e7ff8d08",
            "placeholder": "​",
            "style": "IPY_MODEL_541b2e7d18384849bb7138445a50765f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d65ee576ab804fb1a150b0f224148f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc573d00e224fcda3448d956c13d3bf",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ef551506bcb428493e9c24cc65fdc24",
            "value": 2
          }
        },
        "7f5f026876bc443aa6d31d65e8173ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6dc560545d47b4a66f8f15c013e498",
            "placeholder": "​",
            "style": "IPY_MODEL_6e1fba05d5d9406c884358ee4406ed29",
            "value": " 2/2 [00:10&lt;00:00,  4.74s/it]"
          }
        },
        "0c70df7c95f7493b892797d7324b6111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce5259d7294430cb6edd545e7ff8d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541b2e7d18384849bb7138445a50765f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc573d00e224fcda3448d956c13d3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef551506bcb428493e9c24cc65fdc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a6dc560545d47b4a66f8f15c013e498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1fba05d5d9406c884358ee4406ed29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}